{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.303074 accuracy: 0.078125 [0 / 938]\n",
      "loss: 2.287631 accuracy: 0.218750 [100 / 938]\n",
      "loss: 2.273887 accuracy: 0.250000 [200 / 938]\n",
      "loss: 2.268203 accuracy: 0.390625 [300 / 938]\n",
      "loss: 2.253303 accuracy: 0.328125 [400 / 938]\n",
      "loss: 2.223333 accuracy: 0.515625 [500 / 938]\n",
      "loss: 2.235642 accuracy: 0.312500 [600 / 938]\n",
      "loss: 2.203082 accuracy: 0.437500 [700 / 938]\n",
      "loss: 2.211604 accuracy: 0.296875 [800 / 938]\n",
      "loss: 2.176794 accuracy: 0.531250 [900 / 938]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.176627 accuracy: 0.375000 [0 / 938]\n",
      "loss: 2.168037 accuracy: 0.406250 [100 / 938]\n",
      "loss: 2.118265 accuracy: 0.468750 [200 / 938]\n",
      "loss: 2.137598 accuracy: 0.484375 [300 / 938]\n",
      "loss: 2.086800 accuracy: 0.515625 [400 / 938]\n",
      "loss: 2.024076 accuracy: 0.578125 [500 / 938]\n",
      "loss: 2.065770 accuracy: 0.484375 [600 / 938]\n",
      "loss: 1.984468 accuracy: 0.593750 [700 / 938]\n",
      "loss: 2.017170 accuracy: 0.453125 [800 / 938]\n",
      "loss: 1.930746 accuracy: 0.578125 [900 / 938]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.952414 accuracy: 0.484375 [0 / 938]\n",
      "loss: 1.927360 accuracy: 0.515625 [100 / 938]\n",
      "loss: 1.822378 accuracy: 0.625000 [200 / 938]\n",
      "loss: 1.871445 accuracy: 0.500000 [300 / 938]\n",
      "loss: 1.755583 accuracy: 0.593750 [400 / 938]\n",
      "loss: 1.693483 accuracy: 0.671875 [500 / 938]\n",
      "loss: 1.733987 accuracy: 0.578125 [600 / 938]\n",
      "loss: 1.622230 accuracy: 0.640625 [700 / 938]\n",
      "loss: 1.676212 accuracy: 0.546875 [800 / 938]\n",
      "loss: 1.550553 accuracy: 0.656250 [900 / 938]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/03/19 11:15:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run enchanting-robin-477 at: http://localhost:8080/#/experiments/0/runs/b0f1ee61fedb4519a1e0f82e1be48860\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "mlflow.set_tracking_uri('http://localhost:8080')\n",
    "\n",
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "\n",
    "# Get cpu or gpu for training.\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"mps\"\n",
    "\n",
    "\n",
    "# Define the model.\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        accuracy = metrics_fn(pred, y)\n",
    "\n",
    "        # Backpropagation.\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            mlflow.log_metric(\"loss\", f\"{loss:3f}\", step=(batch // 100))\n",
    "            mlflow.log_metric(\n",
    "                \"accuracy\", f\"{accuracy:3f}\", step=(batch // 100))\n",
    "            print(\n",
    "                f\"loss: {loss:3f} accuracy: {accuracy:3f} [{current} / {len(dataloader)}]\"\n",
    "            )\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    params = {\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"batch_size\": 64,\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"metric_function\": metric_fn.__class__.__name__,\n",
    "        \"optimizer\": \"SGD\",\n",
    "    }\n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer)\n",
    "\n",
    "    # Save the trained model to MLflow.\n",
    "    mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9912422/9912422 [00:00<00:00, 38644308.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/train-images-idx3-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28881/28881 [00:00<00:00, 1641516.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/train-labels-idx1-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1648877/1648877 [00:00<00:00, 12340220.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/t10k-images-idx3-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4542/4542 [00:00<00:00, 3435622.86it/s]\n",
      "INFO: GPU available: True (mps), used: True\n",
      "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (mps), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "/Users/yinnnyou/anaconda3/envs/mlflow/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "WARNING: Missing logger folder: /Users/yinnnyou/workspace/mlflow_framework/lightning_logs\n",
      "WARNING:lightning.fabric.loggers.csv_logs:Missing logger folder: /Users/yinnnyou/workspace/mlflow_framework/lightning_logs\n",
      "INFO: \n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | l1       | Linear             | 7.9 K \n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n",
      "INFO:lightning.pytorch.callbacks.model_summary:\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | l1       | Linear             | 7.9 K \n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n",
      "/Users/yinnnyou/anaconda3/envs/mlflow/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/yinnnyou/anaconda3/envs/mlflow/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw/t10k-labels-idx1-ubyte.gz to /Users/yinnnyou/workspace/mlflow_framework/MNIST/raw\n",
      "\n",
      "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.10it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/19 11:19:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 102.73it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/19 11:19:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 104.96it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/19 11:19:13 WARNING mlflow.utils.checkpoint_utils: Checkpoint logging is skipped, because checkpoint 'save_best_only' config is True, it requires to compare the monitored metric value, but the provided monitored metric value is not available.\n",
      "INFO: `Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 86.08it/s, v_num=0] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/03/19 11:19:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run marvelous-shrew-671 at: http://localhost:8080/#/experiments/0/runs/07e0143010d6403b9e47d93d41e6c98b\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/0\n",
      "run_id: 07e0143010d6403b9e47d93d41e6c98b\n",
      "artifacts: ['model/MLmodel', 'model/conda.yaml', 'model/data', 'model/python_env.yaml', 'model/requirements.txt']\n",
      "params: {'foreach': 'None', 'fused': 'None', 'betas': '(0.9, 0.999)', 'differentiable': 'False', 'weight_decay': '0', 'epochs': '3', 'eps': '1e-08', 'capturable': 'False', 'lr': '0.02', 'maximize': 'False', 'optimizer_name': 'Adam', 'amsgrad': 'False'}\n",
      "metrics: {'acc_step': 0.0, 'train_loss_epoch': 1.6329033374786377, 'train_loss_step': 2.323289632797241, 'train_loss': 1.6329033374786377, 'acc_epoch': 0.3125, 'acc': 0.3125}\n",
      "tags: {'Mode': 'training'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import mlflow.pytorch\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "\n",
    "class MNISTModel(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "        self.accuracy = Accuracy(\"multiclass\", num_classes=10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        acc = self.accuracy(pred, y)\n",
    "\n",
    "        # PyTorch `self.log` will be automatically captured by MLflow.\n",
    "        self.log(\"train_loss\", loss, on_epoch=True)\n",
    "        self.log(\"acc\", acc, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "\n",
    "def print_auto_logged_info(r):\n",
    "    tags = {k: v for k, v in r.data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in MlflowClient(\n",
    "    ).list_artifacts(r.info.run_id, \"model\")]\n",
    "    print(f\"run_id: {r.info.run_id}\")\n",
    "    print(f\"artifacts: {artifacts}\")\n",
    "    print(f\"params: {r.data.params}\")\n",
    "    print(f\"metrics: {r.data.metrics}\")\n",
    "    print(f\"tags: {tags}\")\n",
    "\n",
    "\n",
    "# Initialize our model.\n",
    "mnist_model = MNISTModel()\n",
    "\n",
    "# Load MNIST dataset.\n",
    "train_ds = MNIST(\n",
    "    os.getcwd(), train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "# Only take a subset of the data for faster training.\n",
    "indices = torch.arange(32)\n",
    "train_ds = Subset(train_ds, indices)\n",
    "train_loader = DataLoader(train_ds, batch_size=8)\n",
    "\n",
    "# Initialize a trainer.\n",
    "trainer = L.Trainer(max_epochs=3)\n",
    "\n",
    "# Auto log all MLflow entities\n",
    "mlflow.pytorch.autolog()\n",
    "\n",
    "# Train the model.\n",
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(mnist_model, train_loader)\n",
    "\n",
    "# Fetch the auto logged parameters and metrics.\n",
    "print_auto_logged_info(mlflow.get_run(run_id=run.info.run_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
